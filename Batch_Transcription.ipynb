{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b09f9a",
   "metadata": {},
   "source": [
    "# Async audio transcription with the Azure Speech service and Python\n",
    "\n",
    "In this notebook, you'll learn how to read multiple audio files from an Azure Blob Container, then use the Azure Speech service to transcribe the files. \n",
    "\n",
    "> If you're looking to do single-shot speech to text without writing a ton of code, I recommend using the [Speech CLI](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/spx-basics?tabs=windowsinstall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113164c",
   "metadata": {},
   "source": [
    "## Before you get started\n",
    "\n",
    "You'll need:\n",
    "\n",
    "* An [Azure subscription](https://azure.microsoft.com/en-us/free/cognitive-services/)\n",
    "* An [Azure Blob storage container](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal#create-a-container).\n",
    "  * **Note:** For this tutorial you can use mine\n",
    "  * **Note:** You'll need a second container if you want to write the transcripts to storage. Or you can just write them locally. Up to you.\n",
    "* An [Azure Speech service resource](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/overview#create-the-azure-resource) in the S0 pricing tier. This tutorial **won't** work with a *Free (F0)* key.\n",
    "* Install the `requests` and `xmltodict` to your environment. We strongly recommend that you run all of these notebooks in a virtual environment (virtualenv, venv, pyenv, pipenv, etc.). Run this command from your terminal/command line: `pip install requests xmltodict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7397bc",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "\n",
    "The first thing we need to do is import a few modules. Here's what they are and what you'll use them for:\n",
    "1. `requests` - This module is used to make HTTP requests. Since Azure Blob storage and batch transcription are REST services, we'll be making a series of POST and GET requests to send and retrieve data from Azure.\n",
    "2. `xmltodict` - This modules quickly converts XML into a dictionary. From here we're going to turn the dictionary into JSON, which is a bit easier to use. \n",
    "   * **Note**: This is a personal preference, you can use ElementTree if XML is your jam.\n",
    "3. `json` - This module is used to encode and decode JSON. We'll use this module a fair amount in this guide.\n",
    "4. `time` - When we poll for results, we need to use the `time` module to add a delay to our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc556b86",
   "metadata": {},
   "source": [
    "## Get audio file URLs from Azure Blob storage\n",
    "\n",
    "This tutorial presumes that you have audio stored in an Azure Blob Container. If you have your own audio, you can replace this URL with your own, however, this container is publicly accessible and contains open source files created from Project Gutenberg and the Azure Text to Speech service.\n",
    "\n",
    "> **Important**: This container is public. It is set up this way for the tutorial. We recommend using the appropriate security measuures required for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of containers in storage account\n",
    "response = requests.get('https://speechsamples21.blob.core.windows.net/audio-files-test-21/?comp=list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16e443",
   "metadata": {},
   "source": [
    "## Convert XML to JSON and iterate over the response\n",
    "\n",
    "Here we're converting the XML returned by the Azure Blob storage REST API into a dictionary. Then we're encoding and deconding the JSON for use with the Speech service. \n",
    "\n",
    "> About halfway through this code block you'll get a printout of the JSONified response from Azure Blob storage. I'll also say, that if you're comfortable (or prefer) working with XML it won't offend me. Feel free to parse and iterate through the Azure Blob storage response directly â˜º. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617caa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the XML into a dict so we can convert it to JSON\n",
    "# This is a personal preference. If you prefer working with \n",
    "# XML you can use ElementTree.\n",
    "\n",
    "parsed_xml = xmltodict.parse(response.content)\n",
    "json_data = json.dumps(parsed_xml, indent=2)\n",
    "print(json_data)\n",
    "clean_json = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20201813",
   "metadata": {},
   "source": [
    "Before we can call the Speech service, we need a URL for each audio file that we're transcribing. Here, we're going to loop through the JSONified response, pluck out the URLs, and add them to a list as we go. \n",
    "\n",
    "In a bit, we'll pass this list to the Speech service in our transcription request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7128e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of audio URLs we'll send to the Speech service\n",
    "audio_urls = []\n",
    "\n",
    "for i in clean_json:\n",
    "    for blob in clean_json[i]['Blobs']:\n",
    "        for audio_file in clean_json[i]['Blobs'][blob]:\n",
    "            audio_urls.append(audio_file['Url'])\n",
    "            print(f\"Audio added to list: {audio_file['Url']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d6541",
   "metadata": {},
   "source": [
    "## Create a transcription job\n",
    "\n",
    "Here we're sending a batch of audio files to the Azure Speech service to be transcribed. While our request is synchronous, the service will process each audio file asynchronously. \n",
    "\n",
    "Keep in mind, that the service will send a response almost immediately. However, the service may take up to a few minutes to transcribe your audio files depending on how many files you've sent and their size. The response contains a URL (possibly more than one) that we can use to fetch the status of our transcription request.\n",
    "\n",
    "Let's take a look at the request, review the response, and in the next section we'll discuss retrieving the job status and your transcriptions.\n",
    "\n",
    "* `region` - The regions for your Speech resource. For example: \"westus\"\n",
    "* `key` - The key for your Speech resource. \n",
    "* `displayName` - Give your transcription job a unique name. This will help you identify it if you run this more than once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a183046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key and region for Speech resource\n",
    "# You'll use these for all requests in this tutorial\n",
    "region = 'PASTE_YOUR_SPEECH_RESOURCE_REGION'\n",
    "key = 'PASTE_YOUR_SPEECH_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8660472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "speech_base_url = f'https://{region}.api.cognitive.microsoft.com/speechtotext/v3.0/'\n",
    "\n",
    "# Operation\n",
    "operation = 'transcriptions'\n",
    "\n",
    "# Build the request\n",
    "request_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "request_body = {\n",
    "    \"contentUrls\": audio_urls,\n",
    "    \"locale\": \"en-US\",\n",
    "    \"displayName\": \"GIVE_YOUR_JOB_A_NAME\"\n",
    "}\n",
    "\n",
    "request = requests.post(speech_base_url + operation, headers=request_headers, json=request_body)\n",
    "response = request.json()\n",
    "\n",
    "print(json.dumps(response, sort_keys=True, indent=4, ensure_ascii=False, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d06aa",
   "metadata": {},
   "source": [
    "## Get transcription status\n",
    "\n",
    "In the next two sections we're going to show you how to get the status of your transcription job and how to retrieve the transcriptions for each audio file. \n",
    "\n",
    "This specific operation will get the status for all transcription jobs that you've run that haven't been deleted (active and complete). You can call this specific API to determine if your transcription files are ready to be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet will infinitely loop if the previous call fails. \n",
    "# A transcription job must be created before running this basic sample.\n",
    "\n",
    "# Base URL\n",
    "speech_base_url = f'https://{region}.api.cognitive.microsoft.com/speechtotext/v3.0/'\n",
    "\n",
    "# Operation\n",
    "operation = 'transcriptions'\n",
    "\n",
    "request_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "request = requests.get(speech_base_url + operation, headers=request_headers)\n",
    "response = request.json()\n",
    "\n",
    "# I need to clean this up to use the success param.\n",
    "if request.status_code == 200:\n",
    "    while not response['values']:\n",
    "        print('Waiting for service. Trying again in 5 seconds.')\n",
    "        time.sleep(5)\n",
    "        request = requests.get(speech_base_url + operation, headers=request_headers)\n",
    "        response = request.json()      \n",
    "    else: \n",
    "        print(json.dumps(response, sort_keys=True, indent=4, ensure_ascii=False, separators=(',', ': ')))\n",
    "else:        \n",
    "    print(f'Status code: {request.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13fc88",
   "metadata": {},
   "source": [
    "### Get transcriptions of your audio files\n",
    "\n",
    "To get your trancsriptions, you'll need the `['links']['files]` URL from either of these requests (which you've made previously):\n",
    "\n",
    "* Create transcription (POST)\n",
    "* Get transcriptions (GET)\n",
    "\n",
    "In this example, we'll pull the URL from the **Get transcriptions** request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c81752",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_url = response['values'][0]['links']['files']\n",
    "print(transcription_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1006b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "request = requests.get(transcription_url, headers=request_headers)\n",
    "response = request.json()\n",
    "if request.status_code == 200:\n",
    "    while not response['values']:\n",
    "        print('Waiting for service. Trying again in 5 seconds.')\n",
    "        time.sleep(5)\n",
    "        request = requests.get(transcription_url, headers=request_headers)\n",
    "        response = request.json()    \n",
    "    else:\n",
    "        print(json.dumps(response, sort_keys=True, indent=4, ensure_ascii=False, separators=(',', ': ')))\n",
    "else: \n",
    "    print(f'Status code {request.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d469f",
   "metadata": {},
   "source": [
    "## View a raw transcript\n",
    "\n",
    "In the previous section, the script printed a list of audio files that were transcribed with links to their transcripts. Here we're going to grab one of the transcripts from the response and print the output.\n",
    "\n",
    "> If you'd like, you can replace `get_a_transcript` with a `contentUrl` from the previous section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a transcript URL\n",
    "# This code is checking to make sure that we pull down an \n",
    "# actual transcription and not the report\n",
    "\n",
    "if not response['values'][0]['kind'] == 'TranscriptionReport':\n",
    "    get_a_transcript = response['values'][0]['links']['contentUrl']\n",
    "else: \n",
    "    get_a_transcript = response['values'][1]['links']['contentUrl']\n",
    "\n",
    "# Get the transcript\n",
    "requests.get(get_a_transcript).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d40acf",
   "metadata": {},
   "source": [
    "## Delete a job\n",
    "\n",
    "Here we're going to make a GET request to retrieve all activie and completed jobs. Then we're going to delete the first job in that list. \n",
    "\n",
    "> If you prefer, you can manually replace `id` with a job ID of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "speech_base_url = f'https://{region}.api.cognitive.microsoft.com/speechtotext/v3.0/'\n",
    "\n",
    "# Operation\n",
    "operation = 'transcriptions'\n",
    "\n",
    "request_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "request = requests.get(speech_base_url + operation, headers=request_headers)\n",
    "response = request.json()\n",
    "\n",
    "# Get the first job ID\n",
    "id = response['values'][0]['self'].replace(speech_base_url + operation, '')\n",
    "\n",
    "request = requests.delete(speech_base_url + operation + id, headers=request_headers)\n",
    "print(f'Status code: {request.status_code}')\n",
    "if request.status_code == 204:\n",
    "    print(f'Job {id} successfully deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a40c77",
   "metadata": {},
   "source": [
    "## Delete all jobs (optional)\n",
    "\n",
    "> **Important**: This will only work if you have multiple jobs in the transcription service.\n",
    "\n",
    "If you sent multiple jobs to the Speech service for transcription and you need to clear everything, you can use the following snippet to build a list of job IDs and delete them all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_list = []\n",
    "\n",
    "# Base URL\n",
    "speech_base_url = f'https://{region}.api.cognitive.microsoft.com/speechtotext/v3.0/'\n",
    "\n",
    "# Operation\n",
    "operation = 'transcriptions'\n",
    "\n",
    "request_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "request = requests.get(speech_base_url + operation, headers=request_headers)\n",
    "response = request.json()\n",
    "\n",
    "for i in response['values']:\n",
    "    job_id_list.append(i['self'].replace(speech_base_url + operation + '/', ''))\n",
    "\n",
    "\n",
    "for job in job_id_list:\n",
    "    \n",
    "    job_id = f'/{job}'\n",
    "    \n",
    "    request = requests.delete(speech_base_url + operation + job_id , headers=request_headers)\n",
    "    print(f'Status code: {request.status_code}')\n",
    "    if request.status_code == 204:\n",
    "        print(f'Job {id} successfully deleted.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ec1fb",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "The Speech service v3 REST APIs allow you to do more than transcribe audio. They also allow you to create and manage custom speech models. To learn more, see the [Speech v3 REST API specification](https://westus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/GetTranscriptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec7c65",
   "metadata": {},
   "source": [
    "## Sample code\n",
    "\n",
    "Sample code for batch transcriiption is available in many programming languages on [GitHub](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/batch).\n",
    "\n",
    "* [Node.js](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/batch/js/node)\n",
    "* [Python](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/batch/python)\n",
    "* [C#](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/batch/csharp)\n",
    "* [Batch ingestion client](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/batch/batch-ingestion-client)\n",
    "\n",
    "## Other tools\n",
    "\n",
    "* [Speech CLI](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/spx-basics?tabs=windowsinstall) - Convert speech to text, text to speech, or run translation tasks from the command line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
